{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "H2FmZxvftfj1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.ops import DeformConv2d\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from isar_dataset import ISARDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6V4fHWkQl_Y7"
      },
      "outputs": [],
      "source": [
        "class LowerConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_blocks = nn.Sequential()  # Use nn.Sequential to hold blocks\n",
        "\n",
        "        in_channels = 1  # Start with 1 input channel (grayscale)\n",
        "        for out_channels, num_repeats in [(8, 4), (16, 3), (32, 3)]:\n",
        "            for _ in range(num_repeats):\n",
        "                self.conv_blocks.append(\n",
        "                    nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=0)\n",
        "                )\n",
        "                self.conv_blocks.append(nn.ReLU())\n",
        "                self.conv_blocks.append(nn.BatchNorm2d(out_channels))\n",
        "                in_channels = out_channels  # Update in_channels for next block\n",
        "\n",
        "            self.conv_blocks.append(nn.MaxPool2d(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_blocks(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VIrQyihkmuyo"
      },
      "outputs": [],
      "source": [
        "class DeformedAffineConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # x = x.view(-1, 1, H, W)\n",
        "        kh, kw = 3, 3\n",
        "\n",
        "        # Expect 4D input tensor (B, C, H, W)\n",
        "        # Offset generators are 2 layer + bilinear interpolation\n",
        "        self.offset_generator1 = nn.Conv2d(32, 2 * kh * kw, kernel_size=3)  # Offset generator\n",
        "        self.deform_conv1 = DeformConv2d(32, 64, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.offset_generator2 = nn.Conv2d(64, 2 * kh * kw, kernel_size=3)  # Offset generator\n",
        "        self.deform_conv2 = DeformConv2d(64, 128, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        offset1 = self.offset_generator1(x)\n",
        "        x = self.deform_conv1(x, offset1)\n",
        "        x = self.pool(self.bn1(F.relu(x)))\n",
        "\n",
        "        offset2 = self.offset_generator2(x)\n",
        "        x = self.deform_conv2(x, offset2)\n",
        "        x = self.bn2(F.relu(x))\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mZrq77esc4sp"
      },
      "outputs": [],
      "source": [
        "class DeformedShrinkConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        kh, kw = 3, 3\n",
        "        self.offset_generator1 = nn.Conv2d(32, 2 * kh * kw, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.deform_conv1 = DeformConv2d(32, 64, kernel_size=3)\n",
        "\n",
        "        self.offset_generator2 = nn.Conv2d(64, 2 * kh * kw, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.deform_conv2 = DeformConv2d(64, 128, kernel_size=3)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        offset1 = self.offset_generator1(x)\n",
        "        x = self.deform_conv1(x, offset1)\n",
        "        x = self.pool(self.bn1(F.relu(x)))\n",
        "\n",
        "        offset2 = self.offset_generator2(x)\n",
        "        x = self.deform_conv2(x, offset2)\n",
        "        x = self.bn2(F.relu(x))\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "atwrHiFlmfSW"
      },
      "outputs": [],
      "source": [
        "class SAISARNet(nn.Module):\n",
        "    def __init__(self, num_classes, F=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Lower ConvNet (Shared)\n",
        "        self.lower_convnet = LowerConvNet()\n",
        "\n",
        "        # Deformed Affine ConvNet (Shares parameters with Lower ConvNet)\n",
        "        self.deform_affine = DeformedAffineConvNet()\n",
        "\n",
        "        # Deformed Shrink ConvNet (Independent Parameters)\n",
        "        self.deform_shrink = nn.Sequential(\n",
        "            LowerConvNet(),\n",
        "            DeformedShrinkConvNet()\n",
        "        )\n",
        "\n",
        "        # Bi-LSTM and Attention\n",
        "        self.bilstm = nn.LSTM(128*6*6, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(256, 1),  # Attention mechanism (2 * hidden_size)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # batch_size, F, _, H, W = x.shape\n",
        "        # x = x.view(-1, 1, H, W)\n",
        "        print('hi')\n",
        "\n",
        "        # Shared Lower ConvNet\n",
        "        features = self.lower_convnet(x)    \n",
        "        print(features.shape)\n",
        "        # features = features.view(batch_size, F, 8, 60, 60)\n",
        "        print('hi')\n",
        "\n",
        "        reference_frame = features[0, :, :, :].unsqueeze(0)\n",
        "\n",
        "        print('hi')\n",
        "        # Global Adjustment\n",
        "        global_params = self.deform_affine(reference_frame)\n",
        "        print(global_params.shape)\n",
        "        global_params = global_params.view(-1, 2, 3)\n",
        "\n",
        "        print('hi')\n",
        "        # Apply affine transformation to all frames\n",
        "        adjusted_features = []\n",
        "        for f in range(F):\n",
        "            grid = F.affine_grid(global_params, x[:, f].size(), align_corners=False)\n",
        "            transformed_frame = F.grid_sample(x[:, f], grid, align_corners=False)\n",
        "            adjusted_features.append(transformed_frame)\n",
        "        adjusted_features = torch.stack(adjusted_features, dim=1)\n",
        "        print('hi')\n",
        "\n",
        "        # Local Adjustment\n",
        "        shrink_features = self.deform_shrink(features)\n",
        "\n",
        "        # Bi-LSTM and Attention\n",
        "        shrink_features = shrink_features.view(shrink_features.size(0), -1)\n",
        "        lstm_out, _ = self.bilstm(shrink_features)\n",
        "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
        "        weighted_lstm_out = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "        print('hi')\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(weighted_lstm_out)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jWLjefbmVmE"
      },
      "source": [
        "## Temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5tr8JfVmmXza"
      },
      "outputs": [],
      "source": [
        "# pass\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torchvision.ops import DeformConv2d\n",
        "\n",
        "# class SAISARNet(nn.Module):\n",
        "#     # ... (your existing __init__ method remains the same)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch_size, F, _, H, W = x.shape  # Get dimensions (assuming input shape: (batch_size, F, 1, H, W))\n",
        "#         x = x.view(-1, 1, H, W)  # Reshape for lower_convnet (batch_size * F, 1, H, W)\n",
        "\n",
        "#         # Shared Lower ConvNet\n",
        "#         features = self.lower_convnet(x)\n",
        "#         features = features.view(batch_size, F, 32, 9, 9)  # Reshape back to (batch_size, F, 32, 9, 9)\n",
        "\n",
        "#         # Global Adjustment\n",
        "#         global_params = self.deform_affine(features[:, 0])\n",
        "#         global_params = global_params.view(-1, 2, 3)\n",
        "\n",
        "#         # Apply affine transformation to all frames\n",
        "#         adjusted_features = []\n",
        "#         for f in range(F):\n",
        "#             grid = F.affine_grid(global_params, x[:, f].size(), align_corners=False)\n",
        "#             transformed_frame = F.grid_sample(x[:, f], grid, align_corners=False)\n",
        "#             adjusted_features.append(transformed_frame)\n",
        "#         adjusted_features = torch.stack(adjusted_features, dim=1)\n",
        "\n",
        "#         # Local Adjustment\n",
        "#         shrink_features = self.deform_shrink(adjusted_features)\n",
        "#         shrink_features = shrink_features.view(batch_size, F, -1)  # Flatten for LSTM\n",
        "\n",
        "#         # Bi-LSTM and Attention\n",
        "#         lstm_out, _ = self.bilstm(shrink_features)\n",
        "\n",
        "#         attention_weights = self.attention(lstm_out)  # Calculate attention weights\n",
        "#         attention_weights = torch.softmax(attention_weights, dim=1)\n",
        "\n",
        "#         # Apply attention and aggregate features\n",
        "#         weighted_features = torch.bmm(lstm_out.transpose(1, 2), attention_weights).squeeze(2)\n",
        "\n",
        "#         # Classification\n",
        "#         output = self.classifier(weighted_features)\n",
        "#         return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3aRVmGevdwGt"
      },
      "outputs": [],
      "source": [
        "# pass\n",
        "# class SAISARNet(nn.Module):\n",
        "#     def __init__(self, num_classes, F=3):  # F: number of frames in the sequence\n",
        "#         super().__init__()\n",
        "\n",
        "#         # self.conv_layers = nn.Sequential(\n",
        "#         #     # Block 1: Conv.8@3x3, BN/ReLU x4\n",
        "#         #     nn.Conv2d(1, 8, kernel_size=3, padding=0),  # 1 input channel (grayscale)\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(8),\n",
        "#         #     nn.Conv2d(8, 8, kernel_size=3, padding=0),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(8),\n",
        "#         #     nn.Conv2d(8, 8, kernel_size=3, padding=0),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(8),\n",
        "#         #     nn.Conv2d(8, 8, kernel_size=3, padding=0),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(8),\n",
        "#         #     nn.MaxPool2d(2, 2))\n",
        "\n",
        "#         #     # Block 2: Conv.16@3x3, BN/ReLU x3\n",
        "#         # self.conv_layer2 = nn.Sequential(\n",
        "#         #     nn.Conv2d(8, 16, kernel_size=3),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(16),\n",
        "#         #     nn.Conv2d(16, 16, kernel_size=3),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(16),\n",
        "#         #     nn.Conv2d(16, 16, kernel_size=3),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(16),\n",
        "#         #     nn.MaxPool2d(2, 2))\n",
        "#         # self.conv_layer3 = nn.Sequential(\n",
        "#         #     # # Block 3: Conv.16@3x3, BN/ReLU x3\n",
        "#         #     nn.Conv2d(16, 32, kernel_size=3),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(32),\n",
        "#         #     nn.Conv2d(32, 32, kernel_size=3),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(32),\n",
        "#         #     nn.Conv2d(32, 32, kernel_size=3),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(32),\n",
        "#         #     nn.MaxPool2d(2, 2))  # Output 32x9x9\n",
        "\n",
        "\n",
        "#         def forward(self, x):\n",
        "#             return self.conv_layer2(self.conv_layers(x))\n",
        "\n",
        "#         # Lower ConvNet (Shared)\n",
        "#         # self.lower_convnet = nn.Sequential(*layers)\n",
        "#         #     nn.Conv2d(1, 8, kernel_size=3, padding=1),  # Input 1 channel (grayscale)\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(8),\n",
        "#         #     nn.MaxPool2d(2, 2),\n",
        "\n",
        "#         #     nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(16),\n",
        "#         #     nn.MaxPool2d(2, 2),\n",
        "\n",
        "#         #     nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.BatchNorm2d(32),\n",
        "#         #     nn.MaxPool2d(2, 2)  # Output 32x9x9\n",
        "#         # )\n",
        "\n",
        "#         # Deformed Affine ConvNet\n",
        "#         self.deform_affine = nn.Sequential(\n",
        "#             DeformConv2d(32, 64, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "\n",
        "#             DeformConv2d(64, 128, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Flatten(),\n",
        "#             nn.Linear(128, 6)  # Output affine transformation parameters (2x3)\n",
        "#         )\n",
        "\n",
        "#         # Deformed Shrink ConvNet\n",
        "#         self.deform_shrink = nn.Sequential(\n",
        "#             DeformConv2d(32, 64, kernel_size=3, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2, 2),\n",
        "#             DeformConv2d(64, 128, kernel_size=3, padding=1),\n",
        "#             nn.ReLU()\n",
        "#         )\n",
        "\n",
        "#         # Bi-LSTM and Attention\n",
        "#         self.bilstm = nn.LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "#         self.attention = nn.Sequential(\n",
        "#             nn.Linear(256, 1),  # Attention mechanism (2 * hidden_size)\n",
        "#             nn.Tanh()\n",
        "#         )\n",
        "#         self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "#     # def forward(self, x):\n",
        "#     #     # Assuming input x is (batch_size, F, 120, 120)\n",
        "#     #     x = x.view(-1, 1, 120, 120)  # Reshape for lower_convnet\n",
        "\n",
        "#     #     # Shared Lower ConvNet\n",
        "#     #     features = self.lower_convnet(x)\n",
        "#     #     features = features.view(-1, F, 32, 9, 9)  # Reshape back to (batch_size, F, 32, 9, 9)\n",
        "\n",
        "#     #     # Global Adjustment\n",
        "#     #     global_params = self.deform_affine(features[:, 0])  # Use the first frame for global adjustment\n",
        "#     #     global_params = global_params.view(-1, 2, 3)\n",
        "\n",
        "#     #     # Apply affine transformation to all frames\n",
        "#     #     adjusted_features = []\n",
        "#     #     for f in range(F):\n",
        "#     #         grid = nn.functional.affine_grid(global_params, x[:, f].size(), align_corners=False)\n",
        "#     #         transformed_frame = nn.functional.grid_sample(x[:, f], grid, align_corners=False)\n",
        "#     #         adjusted_features.append(transformed_frame)\n",
        "#     #     adjusted_features = torch.stack(adjusted_features, dim=1)\n",
        "\n",
        "#     #     # Local Adjustment\n",
        "#     #     shrink_features = self.deform_shrink(adjusted_features)\n",
        "\n",
        "#     #     # Bi-LSTM and Attention\n",
        "#     #     shrink_features = shrink_features.view(shrink_features.size(0), -1)\n",
        "#     #     lstm_out, _ = self.bilstm(shrink_features)\n",
        "#     #     attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
        "#     #     weighted_lstm_out = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "\n",
        "\n",
        "#     #     return output  # Classification output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fquKAf2mZNU"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "G_NfF1Rq2fk1"
      },
      "outputs": [],
      "source": [
        "class_names = {\n",
        "    0: 'Satellite',\n",
        "    1: 'Asteroid',\n",
        "    2: 'Idk',\n",
        "    3: 'Idk2'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "u1y268rwq7ne",
        "outputId": "4902ce11-aea2-4931-d9c4-67ed61383566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 120, 120])\n",
            "hi\n",
            "torch.Size([2, 32, 9, 9])\n",
            "hi\n",
            "hi\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 128, 1, 1])",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[49], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Testing sizes\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower ConvNet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mlower_convnet(image_batch)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# print(f'Deformed affine ConvNet: {model.deform_affine(image_batch).shape}')\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[45], line 40\u001b[0m, in \u001b[0;36mSAISARNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Global Adjustment\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m global_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeform_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(global_params\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     42\u001b[0m global_params \u001b[38;5;241m=\u001b[39m global_params\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[43], line 28\u001b[0m, in \u001b[0;36mDeformedAffineConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m offset2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset_generator2(x)\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeform_conv2(x, offset2)\n\u001b[1;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\functional.py:2507\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2495\u001b[0m         batch_norm,\n\u001b[0;32m   2496\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2504\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2505\u001b[0m     )\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m-> 2507\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m   2510\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m   2511\u001b[0m )\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\functional.py:2475\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2473\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 128, 1, 1])"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training Setup\n",
        "center_crop = transforms.CenterCrop(size=(120, 120)) # 250 x 170 optimal, but paper uses 120 x 120\n",
        "\n",
        "dataset = ISARDataset('test/test_labels.csv', r'test/data', transform=center_crop)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=3, shuffle=False)\n",
        "\n",
        "model = SAISARNet(num_classes=4)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "image_batch, label_batch = next(iter(train_dataloader))\n",
        "image, label = image_batch[0], int(label_batch[0])\n",
        "\n",
        "# Fix colormap (scuffed)\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, 256))  # Get colors from viridis\n",
        "colors[0] = [0, 0, 0, 1]                       # Set first color to blackhow print(cmap[0])\n",
        "cmap = ListedColormap(colors)  # Normalize colors to [0, 1]\n",
        "\n",
        "# Display first image\n",
        "plt.imshow(image.permute(1, 2, 0), cmap=cmap)\n",
        "plt.title(class_names[label])\n",
        "plt.axis('off')\n",
        "\n",
        "# Testing sizes\n",
        "print(image_batch.shape)\n",
        "print(model(image_batch).shape)\n",
        "print(f'Lower ConvNet: {model.lower_convnet(image_batch).shape}')\n",
        "# print(f'Deformed affine ConvNet: {model.deform_affine(image_batch).shape}')\n",
        "print(f'Deformed shrink ConvNet: {model.deform_shrink(image_batch).shape}')\n",
        "\n",
        "# # Training Loop (Conceptual)\n",
        "# for epoch in range(num_epochs):\n",
        "#     for images, labels in train_loader:\n",
        "#         # ... training logic (zero gradients, forward pass, loss calculation, backward pass, optimization step)\n",
        "\n",
        "# # Evaluation Loop (Conceptual)\n",
        "# with torch.no_grad():\n",
        "#     for images, labels in test_loader:\n",
        "#         # ... evaluation logic (model prediction, accuracy calculation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9ilKlwfvUyF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hi\n",
            "hi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [8, 1, 3, 3], expected input[1, 29, 9, 9] to have 1 channels, but got 29 channels instead",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[463], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients from the previous iteration\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()         \u001b[38;5;66;03m# Backpropagation to calculate gradients\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[458], line 39\u001b[0m, in \u001b[0;36mSAISARNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Global Adjustment\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m global_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeform_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m global_params \u001b[38;5;241m=\u001b[39m global_params\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[455], line 22\u001b[0m, in \u001b[0;36mLowerConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Users\\wzsmith\\.conda\\envs\\torch-test\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 1, 3, 3], expected input[1, 29, 9, 9] to have 1 channels, but got 29 channels instead"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm  # Progress bar (optional, but highly recommended)\n",
        "\n",
        "num_classes = 4\n",
        "\n",
        "# Training Setup\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "model = SAISARNet(num_classes=num_classes)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate as needed\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10  # Set the desired number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")  # Progress bar\n",
        "\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients from the previous iteration\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()         # Backpropagation to calculate gradients\n",
        "        optimizer.step()        # Update model parameters\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update progress bar with loss and accuracy\n",
        "        progress_bar.set_postfix({'loss': loss.item(), 'accuracy': 100 * correct / total})\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f} Train Acc: {100 * correct / total:.2f}%\")\n",
        "\n",
        "# Save the Model (Optional)\n",
        "torch.save(model.state_dict(), \"saisar_net_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6BCNJPkeBEp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.ops import DeformConv2d  # Install torchvision if not already installed\n",
        "\n",
        "class SAISARNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SAISARNet, self).__init__()\n",
        "\n",
        "        # Global Image Adjustment\n",
        "        self.global_conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=3, padding=1),  # Input channels: 1 (grayscale)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            DeformConv2d(8, 16, kernel_size=3, padding=1),  # Deformable convolution\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Local Image Adjustment\n",
        "        self.local_conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            DeformConv2d(8, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Bi-LSTM and Attention\n",
        "        self.bilstm = nn.LSTM(input_size=16 * 14 * 14, hidden_size=128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(256, 1),  # Two directions * hidden_size\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        global_features = self.global_conv(x)  # (batch_size, 16, 14, 14)\n",
        "        local_features = self.local_conv(x)   # (batch_size, 16, 14, 14)\n",
        "\n",
        "        # Combine global and local features (choose one method)\n",
        "        # Method 1: Concatenate along channel dimension\n",
        "        # combined_features = torch.cat((global_features, local_features), dim=1)  # (batch_size, 32, 14, 14)\n",
        "\n",
        "        # Method 2: Add the features\n",
        "        combined_features = global_features + local_features\n",
        "\n",
        "        # Flatten for LSTM input\n",
        "        combined_features = combined_features.view(combined_features.size(0), -1, combined_features.size(1))\n",
        "\n",
        "        # Bi-LSTM\n",
        "        lstm_out, _ = self.bilstm(combined_features)\n",
        "\n",
        "        # Attention\n",
        "        attention_weights = self.attention(lstm_out)\n",
        "        attention_weights = torch.softmax(attention_weights, dim=1)  # Normalize attention weights\n",
        "        weighted_lstm_out = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(weighted_lstm_out)\n",
        "        return output\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4jWLjefbmVmE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
